use crate::dqn_model::DqnModel;
use crate::replay_loader::load_replay_csv;
use crate::replay_log::ReplaySample;
use crate::train::train_step;
use crate::types::B;

use burn::optim::{AdamConfig, Optimizer};
use burn::tensor::backend::Backend;

pub fn run_training(csv_path: &str, epochs: usize, batch_size: usize) {
    let device = <B as Backend>::Device::default();

    // ëª¨ë¸ & ì˜µí‹°ë§ˆì´ì € ì´ˆê¸°í™”
    let mut model = DqnModel::new(&device);
    let mut optimizer = AdamConfig::new().init::<B, DqnModel>().into();

    // CSVì—ì„œ í•™ìŠµ ìƒ˜í”Œ ë¡œë“œ
    let dataset: Vec<ReplaySample> = load_replay_csv(csv_path, &device);

    if dataset.len() < batch_size {
        println!(
            "â— ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. ({} < {})",
            dataset.len(),
            batch_size
        );
        return;
    }

    println!(
        "ğŸ”§ í•™ìŠµ ì‹œì‘: ì´ {} ì—í¬í¬, ë°°ì¹˜ í¬ê¸° {}",
        epochs, batch_size
    );

    for epoch in 1..=epochs {
        // ë¬´ì‘ìœ„ ì…”í”Œ + ë°°ì¹˜ ì¶”ì¶œ
        use rand::seq::SliceRandom;
        let mut rng = rand::thread_rng();
        let batch: Vec<ReplaySample> = dataset
            .choose_multiple(&mut rng, batch_size)
            .cloned()
            .collect();

        let (new_model, new_optimizer, loss) = train_step(model, optimizer, batch);
        model = new_model;
        optimizer = new_optimizer;

        println!("ğŸ“š Epoch {:>3} | Loss: {:.6}", epoch, loss);
    }

    println!("âœ… í•™ìŠµ ì™„ë£Œ!");
}
